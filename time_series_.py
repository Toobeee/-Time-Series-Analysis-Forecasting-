# -*- coding: utf-8 -*-
"""Time series .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G8yfcHCuOnY5gzfx_Qp0SzI_c12QgziN
"""

!pip install yfinance --quiet

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from math import sqrt
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Input, LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
import pprint

"""Download historical daily stock prices using yfinance."""

import yfinance as yf

# Download Tesla (TSLA) stock data
df = yf.download("TSLA", start="2019-01-01", end="2024-12-31")

# Keep only the 'Close' price and rename it to 'price'
df = df[['Close']].rename(columns={'Close': 'price'})

# Drop any missing values
df.dropna(inplace=True)

# Display the first rows
print(df.head())

# Split
train_size = int(len(df) * 0.8)
train_df = df.iloc[:train_size]
test_df = df.iloc[train_size:]

# Scale only on training data
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train_df[['price']])
test_scaled = scaler.transform(test_df[['price']])

from sklearn.metrics import mean_squared_error, mean_absolute_error
from math import sqrt

def multi_step_metrics(y_true, y_pred):
    metrics = {}
    forecast_horizon = y_true.shape[1]
    for step in range(forecast_horizon):
        mse = mean_squared_error(y_true[:, step], y_pred[:, step])
        mae = mean_absolute_error(y_true[:, step], y_pred[:, step])
        rmse = sqrt(mse)
        mape = np.mean(np.abs((y_true[:, step] - y_pred[:, step]) / y_true[:, step])) * 100
        metrics[f"Step {step+1}"] = {
            'MAE': mae,
            'MSE': mse,
            'RMSE': rmse,
            'MAPE': mape
        }
    return metrics

df.head(10)

"""- Visualize the Close price over time."""

# Keep the same plot function
def plot_df(df, x, y, title="", xlabel='Date', ylabel='Price', dpi=100):
    plt.figure(figsize=(15,4), dpi=dpi)
    plt.plot(x, y, color='tab:red')

    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)
    plt.xticks(rotation=90)
    plt.show()

# Call it for Tesla
plot_df(
    df,
    x=df.index,          # the index is the Date
    y=df['price'],       # your column is named 'price'
    title='Tesla Stock Closing Price (2019–2024)',
    ylabel='Closing Price (USD)'
)

"""Calculate 7-day and 30-day moving averages

- Rolling moving averages (7-day, 30-day)
"""

# 7-day moving average
df['MA7'] = df['price'].rolling(window=7).mean()

# 30-day moving average
df['MA30'] = df['price'].rolling(window=30).mean()

plt.figure(figsize=(15,6), dpi=100)

plt.plot(df.index, df['price'], label='Closing Price', color='blue')
plt.plot(df.index, df['MA7'], label='7-day MA', color='orange')
plt.plot(df.index, df['MA30'], label='30-day MA', color='red')

plt.title('Tesla Closing Price with 7-day & 30-day Moving Averages')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()
plt.xticks(rotation=90)
plt.show()

"""7-day MA → short-term trend
Shows quick changes, more sensitive to recent price moves.


30-day MA → long-term trend
Smooths out more noise, shows the broader direction.

Seasonal decomposition of the series (using seasonal_decompose)
"""

from statsmodels.tsa.seasonal import seasonal_decompose

# !pip install statsmodels

from statsmodels.tsa.seasonal import seasonal_decompose
import matplotlib.pyplot as plt

# ✅ Multiplicative Decomposition
multiplicative_decomposition = seasonal_decompose(df['price'], model='multiplicative', period=30)

# ✅ Additive Decomposition
additive_decomposition = seasonal_decompose(df['price'], model='additive', period=30)

# ✅ Plot Multiplicative
plt.rcParams.update({'figure.figsize': (16, 12)})
multiplicative_decomposition.plot().suptitle('Tesla - Multiplicative Decomposition', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

# ✅ Plot Additive
additive_decomposition.plot().suptitle('Tesla - Additive Decomposition', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])

plt.show()

"""- Plot ACF/PACF to understand lags and correlations."""

# ------------------------------------
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
# 2️⃣ Plot ACF
# ------------------------------------
plt.figure(figsize=(12, 5))
plot_acf(df['price'], lags=50)
plt.title('Tesla Closing Price - Autocorrelation (ACF)')
plt.show()

# ------------------------------------
# 3️⃣ Plot PACF
# ------------------------------------
plt.figure(figsize=(12, 5))
plot_pacf(df['price'], lags=50, method='ywm')  # 'ywm' = Yule-Walker Modified
plt.title('Tesla Closing Price - Partial Autocorrelation (PACF)')
plt.show()

# Create subplot
fig, axes = plt.subplots(1, 2, figsize=(16, 4), dpi=100)

# Plot ACF
plot_acf(df['price'], lags=50, ax=axes[0])
axes[0].set_title('Tesla Closing Price - ACF')

# Plot PACF
plot_pacf(df['price'], lags=50, ax=axes[1], method='ywm')  # 'ywm' is more robust
axes[1].set_title('Tesla Closing Price - PACF')

"""- Comment on stationarity and apply differencing if needed."""

# Create the first difference series
df['price_diff'] = df['price'].diff()

# Drop NaN created by differencing
df_diff = df['price_diff'].dropna()

# Plot the differenced series
plt.figure(figsize=(15, 5))
plt.plot(df_diff)
plt.title('Tesla Price - First Difference')
plt.xlabel('Date')
plt.ylabel('Price Difference')
plt.show()

"""After first differencing, your series appears stationary:

✅ Mean is stable → fluctuates around 0.

✅ No trend → differencing removed it.

✅ Variance mostly constant → no clear pattern of increasing volatility.

# TASK 2

2. ARIMA Benchmark
"""

#- Fit an appropriate ARIMA or SARIMA model on the Close price.
# go for ARIMA
# !pip install pmdarima

!pip install --upgrade pip
!pip install Cython
!pip install numpy
!pip install pmdarima

from statsmodels.tsa.arima.model import ARIMA

!pip install --upgrade numpy
!pip uninstall -y pmdarima
!pip install pmdarima

# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error, mean_absolute_error

train_size = int(len(df) * 0.8)
train = df['price'].iloc[:train_size]
test = df['price'].iloc[train_size:]

# STEP 3: Fit ARIMA model — try ARIMA(5,1,0) as a starting point
model = ARIMA(train, order=(5,1,0))  # (p,d,q) ← tweak if needed
model_fit = model.fit()

# STEP 4: Forecast
forecast = model_fit.forecast(steps=len(test))

# STEP 5: Plot actual vs forecast
plt.figure(figsize=(12,5))
plt.plot(train.index, train, label='Train')
plt.plot(test.index, test, label='Test', color='green')
plt.plot(test.index, forecast, label='Forecast', color='red')
plt.title('ARIMA Forecast vs Actual - Tesla Stock Price')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()

# STEP 6: Evaluation
mse = mean_squared_error(test, forecast)
mae = mean_absolute_error(test, forecast)
rmse = np.sqrt(mse)

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")

"""- Use AIC to guide order selection."""

# STEP 2: Train-test split
train_size = int(len(df) * 0.8)
train = df['price'].iloc[:train_size]
test = df['price'].iloc[train_size:]

# STEP 2: Train-test split
train_size = int(len(df) * 0.8)
train = df['price'].iloc[:train_size]
test = df['price'].iloc[train_size:]

# STEP 3: Try different ARIMA orders and compare AIC
best_aic = np.inf
best_order = None
best_model = None

for p in range(0, 4):
    for d in range(0, 3):
        for q in range(0, 4):
            try:
                model = ARIMA(train, order=(p,d,q))
                model_fit = model.fit()
                aic = model_fit.aic
                if aic < best_aic:
                    best_aic = aic
                    best_order = (p,d,q)
                    best_model = model_fit
                print(f"ARIMA{(p,d,q)} - AIC:{aic:.2f}")
            except:
                continue

# STEP 4: Summary of best model
print(f"\n✅ Best ARIMA Order: {best_order} with AIC = {best_aic:.2f}")

# STEP 5: Forecast using best model
forecast = best_model.forecast(steps=len(test))

# STEP 6: Plot
plt.figure(figsize=(12,5))
plt.plot(train.index, train, label='Train')
plt.plot(test.index, test, label='Test')
plt.plot(test.index, forecast, label='Forecast', color='red')
plt.title(f"Best ARIMA{best_order} Forecast vs Actual")
plt.legend()
plt.grid(True)
plt.show()

# STEP 7: Evaluation
mse = mean_squared_error(test, forecast)
mae = mean_absolute_error(test, forecast)
rmse = np.sqrt(mse)
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")

"""# 3. Forecast the next 30 days"""

forecast = model_fit.forecast(steps=30)

# 4. Create future dates
last_date = df.index[-1]
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30, freq='B')  # 'B' = business day

# 5. Plot forecast
plt.figure(figsize=(12, 5))
plt.plot(df.index, df['price'], label='Historical')
plt.plot(future_dates, forecast, label='Forecast (Next 30 Days)', color='red')
plt.title("Tesla Stock Price Forecast - Next 30 Days")
plt.xlabel("Date")
plt.ylabel("Price")
plt.legend()
plt.grid(True)
plt.show()

# 6. Print forecast values (optional)
forecast_df = pd.DataFrame({'Date': future_dates, 'Forecasted Price': forecast})
print(forecast_df)

""" Forecast with Confidence Intervals

"""

# 2. Fit ARIMA(3,1,2) model on the full dataset
model = ARIMA(df['price'], order=(3, 1, 2))
model_fit = model.fit()

# 3. Forecast next 30 days with confidence intervals
forecast_result = model_fit.get_forecast(steps=30)
forecast = forecast_result.predicted_mean
conf_int = forecast_result.conf_int()

# 4. Create future dates
last_date = df.index[-1]
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30, freq='B')

# 5. Plot
plt.figure(figsize=(12, 6))
plt.plot(df.index, df['price'], label='Historical')
plt.plot(future_dates, forecast, label='Forecast', color='red')
plt.fill_between(future_dates,
                 conf_int.iloc[:, 0],
                 conf_int.iloc[:, 1],
                 color='pink', alpha=0.3, label='Confidence Interval')
plt.title("Tesla Stock Price Forecast (Next 30 Days) with Confidence Intervals")
plt.xlabel("Date")
plt.ylabel("Price")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA

# 1. Load full Tesla data
df = yf.download("TSLA", start="2019-01-01", end="2024-12-31")
df = df[['Close']].rename(columns={'Close': 'price'})
df.dropna(inplace=True)

# 2. Train/test split
train_size = int(len(df) * 0.8)
train = df.iloc[:train_size]
test = df.iloc[train_size:]

# 3. Fit ARIMA on train data
model = ARIMA(train['price'], order=(3, 1, 2))
model_fit = model.fit()

# 4. Forecast same length as test
forecast_result = model_fit.get_forecast(steps=len(test))
forecast = forecast_result.predicted_mean
conf_int = forecast_result.conf_int()
forecast.index = test.index  # Align with test dates

# 5. Plot: forecast + confidence + true values
plt.figure(figsize=(12, 6))
plt.plot(train.index, train['price'], label='Train')
plt.plot(test.index, test['price'], label='Actual Test', color='green')
plt.plot(forecast.index, forecast, label='Forecast', color='red')
plt.fill_between(forecast.index,
                 conf_int.iloc[:, 0],
                 conf_int.iloc[:, 1],
                 color='pink', alpha=0.3, label='95% CI')
plt.title("ARIMA Forecast vs True Tesla Prices")
plt.xlabel("Date")
plt.ylabel("Price")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""Final Report (Example Template)
Model: ARIMA(3,1,2)
MAE: 9.37
RMSE: 11.22

Why this model?
The ARIMA(3,1,2) model was selected using AIC minimization via auto_arima.

PACF supported 3 AR lags.

1st difference made the series stationary.

ACF suggested 2 MA lags.

It provides a good trade-off between simplicity and accuracy based on AIC and forecast performance.

## 3. Deep Learning Forecasting with LSTM
"""

# Prepare the dataset for supervised learning using a sliding window approach.

def create_sequences(data, window=30):
    X, y = [], []
    for i in range(len(data) - window):
        X.append(data[i:i + window])
        y.append(data[i + window])
    return np.array(X), np.array(y)

"""- Split into train/test and scale the data appropriately."""

# Split 80/20
train_size = int(len(df) * 0.8)
train_df = df.iloc[:train_size]
test_df = df.iloc[train_size:]

# Normalize using MinMaxScaler
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train_df[['price']])
test_scaled = scaler.transform(test_df[['price']])

def create_sequences(data, window=30):
    X, y = [], []
    for i in range(len(data) - window):
        X.append(data[i:i + window])
        y.append(data[i + window])
    return np.array(X), np.array(y)

window_size = 30
X_train, y_train = create_sequences(train_scaled, window_size)
X_test, y_test = create_sequences(test_scaled, window_size)

# Reshape for LSTM: [samples, time_steps, features]
X_train = X_train.reshape(-1, window_size, 1)
X_test = X_test.reshape(-1, window_size, 1)

"""- Build an LSTM model to forecast the next day’s Close price:"""

model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(window_size, 1)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

early_stop = EarlyStopping(monitor='val_loss', patience=5)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=50,
    batch_size=32,
    callbacks=[early_stop],
    verbose=1
)

pred_scaled = model.predict(X_test)
y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))
pred_inv = scaler.inverse_transform(pred_scaled)

plt.figure(figsize=(12,5))
plt.plot(y_test_inv, label='Actual Price')
plt.plot(pred_inv, label='Predicted Price')
plt.title('Tesla Close Price: Actual vs Predicted')
plt.xlabel('Days')
plt.ylabel('Price')
plt.legend()
plt.show()

mae = mean_absolute_error(y_test_inv, pred_inv)
rmse = np.sqrt(mean_squared_error(y_test_inv, pred_inv))
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")

"""- Plot true vs predicted on test set"""

plt.figure(figsize=(12, 6))
plt.plot(y_test_inv, label='Actual Price', color='blue')
plt.plot(pred_inv, label='Predicted Price', color='red')
plt.title('True vs Predicted Tesla Closing Price (Test Set)')
plt.xlabel('Days')
plt.ylabel('Price ($)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""## 4. Visualizations & Interpretation"""

!pip install tensorflow

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[['price']])

from statsmodels.tsa.arima.model import ARIMA

# Fit ARIMA model on NON-SCALED train data
arima_model = ARIMA(train['price'], order=(3, 1, 2))
arima_model = arima_model.fit()

# Forecast same number of steps as your test set
arima_forecast = arima_model.forecast(steps=len(test))

# No need to inverse_transform if ARIMA was trained on original price
arima_pred_inv = arima_forecast.values  # or .tolist()

# Ensure LSTM predictions and true values are inverse-transformed
# y_test_inv and y_pred_inv must already be available
min_len = min(len(y_test_inv), len(arima_pred_inv), len(pred_inv))
y_test_plot = y_test_inv[:min_len]
arima_plot = arima_pred_inv[:min_len]
lstm_plot = pred_inv[:min_len]

plt.figure(figsize=(16, 6))

plt.subplot(1, 2, 1)
plt.plot(y_test_plot, label='Actual', color='blue')
plt.plot(arima_plot, label='ARIMA Forecast', color='green')
plt.title('ARIMA: Actual vs Forecast')
plt.xlabel('Days')
plt.ylabel('Price')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(y_test_plot, label='Actual', color='blue')
plt.plot(lstm_plot, label='LSTM Forecast', color='orange')
plt.title('LSTM: Actual vs Forecast')
plt.xlabel('Days')
plt.ylabel('Price')
plt.legend()

plt.tight_layout()
plt.show()

"""

✅ LSTM clearly outperforms ARIMA in this case.

LSTM closely follows the actual price movements, including sharp trends and nonlinear shifts, showing high prediction accuracy.

ARIMA, on the other hand, produces flat, overly smoothed forecasts, failing to capture the underlying volatility and trend reversals.

 This is expected because ARIMA assumes linearity and stationarity, which don't suit highly volatile and nonstationary stock data. LSTM, being a deep learning model, is better at learning complex temporal patterns from data without strong assumptions."""

